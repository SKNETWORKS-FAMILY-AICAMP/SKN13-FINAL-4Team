# LLM (Love Language Model)  
**AI 인플루언서 연애 상담 스트리밍 플랫폼**  

## 📌 목차
1. [프로젝트 개요 및 배경](#-프로젝트-개요-및-배경)  
2. [프로젝트 차별성](#-프로젝트-차별성)  
3. [시장 분석 및 수익화 전략](#-시장-분석-및-수익화-전략)  
4. [기술 스택](#-기술-스택)  
5. [데이터 전처리](#-데이터-전처리)  
6. [ERD & 아키텍처](#-erd--아키텍처)  
7. [모델 성능](#-모델-성능)  
8. [LangChain vs LangGraph](#-langchain-vs-langgraph)  
9. [서버 부하 테스트](#-서버-부하-테스트)  
10. [역할 분담](#-역할-분담)  
11. [참고 자료](#-참고-자료)  


---

## 1. 프로젝트 개요 및 배경 

### 1.1 프로젝트 개요
**LLM(Love Language Model)** 은 AI 인플루언서 캐릭터 중심의 맞춤형 연애 상담을 제공하여, 양방향 소통·실시간 스트리밍·팬덤 형성을 통한 차별화된 경험을 제공한다.  
특징:  
- 네 명의 성격·스타일이 뚜렷한 AI 인플루언서 제공  
- 동일 사연에도 각기 다른 반응과 언어 스타일  
- 팬덤 기반 IP 확장 및 수익화  


### 1.2.1 개인 미디어 시대, 스트리밍 플랫폼의 성장 
스마트폰 보급으로 개인 미디어 시대가 본격화되었고, 유튜브는 TV를 넘어 대중의 주요 미디어 채널로 자리 잡았다. 이는 단순한 시청 방식의 변화가 아니라, 콘텐츠 제작과 소비 주체가 개인 중심으로 이동했다는 점에서 의미가 크다.
최근 데이터에 따르면, 한국 스마트폰 사용자 중 94%가 동영상 앱을 이용하며, 사용시간 점유율 67.4%를 기록한 유튜브가 압도적인 1위를 차지한다.

또한, 스트리밍 플랫폼의 성장은 새로운 미디어 경쟁 구도를 만들어가고 있다. 네이버의 치지직은 2023년 말 첫선을 보인 이후 불과 1년 만에 월 이용자 수 250만 명을 확보하며 빠르게 성장했다. 현재 약 150명의 파트너 스트리머를 보유하고 있으며, 업계에서는 안정적인 서비스 기반으로 단기간에 경쟁력을 강화하고 있다는 평가가 나오고 있다.

특히 치지직과 함께 떠오르는 SOOP 또한 꾸준한 성장세를 보이며 시청자 수 확대를 이어가고 있다. 2024년 10월과 11월 지표에서도 두 플랫폼은 평균 및 최고 시청자 수 모두 상승세를 기록하며, 사용자 선택지가 점점 다양화되고 있음을 보여줍니다.
(여기에 우리 중간 발표 피피티 사진 넣기)

### 1.2.2 스트리머 형식의 가치 
스트리머 콘텐츠의 가장 큰 특징은 **실시간성**이다. 시청자는 단순히 영상을 소비하는 것이 아니라 실시간으로 대화를 주고받으며 정서적 유대감을 형성할 수 있다. 이러한 즉각적인 반응과 교감은 다른 미디어 형식에서는 구현하기 어려운 강점이다.

또한 스트리밍은 **강한 몰입감**을 제공한다. 생동감 있는 현장감을 전달하며, 시청자가 능동적으로 콘텐츠에 참여할 수 있는 구조를 가진다. 채팅, 후원, 참여형 미션 등 다양한 방식으로 관객이 단순한 소비자가 아니라 참여자로서 자리매김한다.

이러한 특성은 자연스럽게 **커뮤니티 형성**으로 이어진다. 스트리머와 시청자 간의 상호작용 속에서 공동체적 경험이 강화되며, 시청자가 단순한 수용자를 넘어 대화의 주체로 자리하게 된다. 결과적으로 스트리머 형식은 유대감, 몰입감, 참여성을 기반으로 기존 미디어보다 훨씬 높은 수준의 관계성과 충성도를 확보할 수 있는 구조적 장점을 가진다.

### 1.2.3 연애 도메인 

연애는 시대와 세대를 막론하고 변하지 않는 인간의 본질적인 관심사입니다. </br>
실제로 유튜브와 라이브 스트리밍 플랫폼에서 연애 관련 콘텐츠는 꾸준히 높은 시청률과 화제성을 기록하며 대중적 인기를 증명하고 있다. 다양한 연애 리얼리티 프로그램과 상담형 콘텐츠가 연령대별로 두터운 시청층을 확보하고 있으며, 이는 연애라는 주제가 세대 전반에 걸쳐 보편적 매력을 지닌다는 점을 보여준다.

연애는 또한 **감정과 언어가 풍부한 도메인**이다. </br>
개인의 경험과 감정을 언어로 풀어내는 과정이 필수적이기 때문에, AI가 자연어 처리와 공감 능력을 발전시키는 데 적합한 학습 영역이 된다. 단순한 정보 제공을 넘어 감정적 반응과 관계적 맥락까지 다루어야 하므로, AI 서비스의 진화와 고도화를 실험할 수 있는 의미 있는 주제라 할 수 있다.

**주제의 보편성과 지속성**도 중요한 이유다. </br>
연애는 시대와 세대를 막론하고 꾸준히 회자되는 주제로, 콘텐츠 생산의 지속 가능성이 높다. 

또한 라이브 방송을 통한 실시간 소통은 **2차 콘텐츠로 확장**될 수 있는 가능성을 내포한다. </br>
상담 클립, 하이라이트, 숏폼 등 다양한 형태의 파생 콘텐츠 제작이 가능해 서비스 확장성과 활용성이 크다.

>> 따라서 연애를 주제로 한 스트리머 기반 기획은 MZ 세대의 관심사, AI 기술 발전의 학습 가치, 콘텐츠 산업적 확장성이라는 세 가지 측면에서 모두 전략적 타당성을 가진다.



---

## 2. 프로젝트 차별성 

## 2.1 차별성 - 기존 연애 상담 서비스와의 비교 
기존의 연애 상담 서비스는 크게 두 가지로 나뉜다. 하나는 심리 상담 중심 서비스로, 전문성이 높지만 접근성이 낮고 비용 부담이 크다는 한계가 있다. 다른 하나는 콘텐츠 소비 중심 서비스로, 다양한 연애 관련 콘텐츠를 제공하지만 일방향적이며 개인 맞춤형 피드백이 부족하다는 문제가 있다.

본 프로젝트는 이 두 가지의 한계를 넘어, 현대인의 외로움과 관계 고민을 해결할 수 있는 신뢰할 수 있는 디지털 연애 멘토를 창조하는 것을 목표로 한다.

핵심 가치:  
1. **일관성 있는 상담 품질** – 사람 상담자가 겪을 수 있는 감정 기복 없이 언제나 일정한 수준의 조언과 피드백을 유지
2. **지속가능한 운영** – 악성 댓글이나 과도한 감정 노동으로부터 자유로움  
3. **공감+분석 결합** – 따뜻한 공감적 대화와 함께 데이터 기반의 현실적인 해결책을 동시에 제시
4. **스트리밍 포맷** – 실시간 1:N 소통을 가능하게 하고, 참여 중심의 커뮤니티를 형성  
5. **익명성 보장** – 누구나 깊은 고민을 안전하게 공유할 수 있는 환경을 제공


### 2.1.1 기대 효과  
- **시장성**: 이미 연애 리얼리티와 상담 콘텐츠의 인기가 입증된 만큼, 대중적 관심과 수요를 확보 가능 
- **수익화**: 프리미엄 상담 서비스, 후원 채팅, 그리고 2차 콘텐츠 제작(IP 확장) 등 다양한 수익 모델을 마련 가능 
- **글로벌 진출**: 다국어 서비스를 통해 한국을 넘어 전 세계 시장으로 확장할 수 있으며, 글로벌 이용자층을 공략 가능 

## 2.2 차별성 - 핵심 기능 
1. **실시간성·안정성·개성화** 
- 웹 소켓 기반의 실시간 채팅 기능을 통해 1:N 소통 구조를 실현. 
- 단순한 일방향 상담이 아니라, 시청자가 즉각적으로 참여하고 반응할 수 있는 양방향 커뮤니티를 가능하게함. 

2. **안정적인 배포와 환경 설졍** 
- Docker·AWS 기반 인프라와 최적화된 배포 환경은 대규모 접속 상황에서도 안정적인 서비스를 제공
- 끊김 없는 상담 경험

3. **페르소나별 개성적인 언어와 비언어적 표현 구현** 
- 단순히 기계적인 답변이 아니라, 각 페르소나의 말투·화법·태도를 반영해 사용자가 상담자와 실제 대화하는 듯한 몰입감을 제공
- 감과 분석이 결합된 새로운 형태의 연애 상담 경험을 완성

---

## 3. 시장 분석 및 수익화 전략  


### 3.1 SWOT 분석  

| 구분 | 내용 |
|------|------|
| **S (강점)** | AI 인플루언서 기반 맞춤형 경험을 제공. |
|             | 개인적 고민과 상황에 맞는 피드백 받을 수 있다. |
|             | 콘텐츠의 재생산성과 IP 확장성이 높아 다양한 형태의 2차 콘텐츠 제작 및 브랜드 확장이 가능.|
| **W (약점)** | AI의 한계와 데이터·윤리 문제 |
|             | 감정적 상담 영역에서는 인간적인 섬세함을 완전히 대체하기 어려움.|
|             | 서비스 운영 과정에서 기술 개발과 유지·보수 비용이 지속 발생 부담 |
| **O (기회)** | 연애와 결혼 시장은 꾸준한 잠재 수요를 가진 영역 |
|             | AI 발전과 결합해 새로운 가치를 창출 가능. 
|             | 특히 글로벌 진출이 용이한 콘텐츠 성격을 지니고 있어, 해외 시장과 미디어 산업과의 시너지를 기대 |
| **T (위협)** | 연애 콘텐츠와 상담 시장은 이미 경쟁이 치열 |
|             | 기존 방송 프로그램, 유튜버, 전문 상담 서비스 등 다양한 경쟁자가 존재
|             | 기술 변화에 대한 빠른 적응이 요구되며, 변화 속도를 따라가지 못할 경우 경쟁력이 약화될 위험 존재|


### 3.2 Business Model  
- **후원·프리미엄 구독** – 실시간 스트리밍에서 시청자의 직접적인 참여와 후원은 중요한 수익원이다. 이용자는 자신이 공감하거나 도움이 된 상담에 대해 즉각적으로 후원을 보낼 수 있으며, 이러한 참여는 단순한 기부가 아니라 커뮤니티와의 상호작용을 강화하는 기능도 수행한다.
- **광고** – 스트리밍 플랫폼과 영상 콘텐츠 특성상 광고 노출 기회가 풍부하며, 다양한 브랜드와의 협업을 통해 안정적인 광고 매출을 확보할 수 있다. 특히 연애·라이프스타일과 관련된 제품·서비스와의 높은 적합성을 바탕으로 맞춤형 광고 집행이 가능하다.
- **DB/IP 사업** – 스트리밍에서 발생한 상담과 대화를 기반으로, 하이라이트 클립·숏폼·리뷰 콘텐츠 등 2차 콘텐츠를 제작할 수 있다. 이는 추가적인 조회 수와 광고 수익을 창출할 뿐 아니라, IP 확장을 통해 브랜드 인지도를 넓히는 효과를 가져온다.

>> 이와 같은 다각화된 수익 구조는 단기적 매출 확보와 장기적 브랜드 가치 확대를 동시에 가능하게 하며, 서비스의 지속성과 확장성을 보장한다.

---

## 4. 기술 스택

<br/><br/>
<p align="center">
  <!-- Programming Languages -->
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white">
  <img src="https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=JavaScript&logoColor=black">
</p>

<p align="center">
  <!-- Dev Environment -->
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=Docker&logoColor=white">
  <img src="https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=Ubuntu&logoColor=white">
  <img src="https://img.shields.io/badge/AWS EC2-FF9900?style=for-the-badge&logo=amazon-ec2&logoColor=white">
  <img src="https://img.shields.io/badge/AWS ElastiCache-FF4F8B?style=for-the-badge&logo=amazonaws&logoColor=white">
  <img src="https://img.shields.io/badge/AWS RDS-527FFF?style=for-the-badge&logo=amazon-rds&logoColor=white">
  <img src="https://img.shields.io/badge/AWS ELB-FF9900?style=for-the-badge&logo=awselasticloadbalancing&logoColor=white">
</p>

<p align="center">
  <!-- Web Server / Frontend -->
  <img src="https://img.shields.io/badge/Nginx-009639?style=for-the-badge&logo=nginx&logoColor=white">
  <img src="https://img.shields.io/badge/React-61DAFB?style=for-the-badge&logo=React&logoColor=black">
</p>

<p align="center">
  <!-- Backend Frameworks -->
  <img src="https://img.shields.io/badge/Django-092E20?style=for-the-badge&logo=django&logoColor=white">
  <img src="https://img.shields.io/badge/Django Channels-44B78B?style=for-the-badge&logo=django&logoColor=white">
  <img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white">
</p>

<p align="center">
  <!-- Database -->
  <img src="https://img.shields.io/badge/PostgreSQL-4169E1?style=for-the-badge&logo=PostgreSQL&logoColor=white">
  <img src="https://img.shields.io/badge/Redis-DC382D?style=for-the-badge&logo=Redis&logoColor=white">
</p>

<p align="center">
  <!-- AI / ML -->
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=PyTorch&logoColor=white">
  <img src="https://img.shields.io/badge/HuggingFace-FFB000?style=for-the-badge&logo=huggingface&logoColor=black">
  <img src="https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=OpenAI&logoColor=white">
  <img src="https://img.shields.io/badge/LangChain-00A98F?style=for-the-badge&logoColor=white">
  <img src="https://img.shields.io/badge/LangGraph-8A2BE2?style=for-the-badge&logoColor=white">
</p>
<br/><br/>


---

## 5. 데이터 전처리 

### 5.1 데이터셋 개요  

- **데이터 출처 및 수집 방법**:  
본 프로젝트의 데이터는 주로 유튜브 영상에서 수집되었다. 다양한 연애 상담 유튜버의 영상을 크롤링한 뒤, mp3 등 음성 파일로 변환하였다. 이후 faster-whisper 라이브러리를 활용하여 음성을 자동으로 전사함으로써 텍스트 기반 스크립트를 확보하였다.

### 5.2 전처리 프로세스 개요  
1. 선정된 유튜브 영상을 크롤링하고 음성 파일로 변환한다.
2. 변환된 음성을 'faster-whisper'로 전사하여 스크립트를 생성한다.
3. 전사된 스크립트 중 페르소나 외 인물이 등장하는 부분은 삭제한다.
4. 최종적으로 페르소나의 말투와 화법을 정의하고, Few-shot Prompting을 활용해 QA 데이터셋으로 변환한다.

### 5.3 이상치 처리  
- **기준**: 이상치 데이터는 주로 페르소나 외 인물이 등장하는 영상에서 발생
- **처리 방식**:  
  - 페르소나 외 인물이 등장하는 구간은 스크립트를 직접 확인하며 불필요한 대화를 수정·삭제
  - 단일 페르소나의 말투와 화법만 유지할 수 있도록 정제 
- **영향**:  
  - 학습 데이터의 톤앤매너 일관성을 강화하였으며, 파인튜닝 과정에서 발생할 수 있는 노이즈를 최소화하였다.

### 5.4 표준화  
- 텍스트 데이터는 sLLM 파인튜닝에 적합한 QA 구조로 변환 
- 각 스크립트는 GPT-4.1에 예시로 제공되었고, Few-shot Prompting을 통해 질문–응답 쌍으로 재구성
- **QA 구조**:  
  - **Q**: 전사된 스크립트를 기반으로 시청자가 실제로 물어볼 법한 질문
  - **A**: 스트리머 페르소나의 톤앤매너를 반영한 답변
이와 같은 구조화를 통해 데이터셋은 모델 학습에 직접 활용할 수 있는 형식으로 표준화되었다.

- **사용 라이브러리**: `json.JSONDecodeError`, `openai`  

### 5.5 데이터 변환 및 생성  
- 최종 데이터셋은 `.json` 형식으로 저장  

---

## 6. ERD, 아키텍처

![ERD](https://github.com/user-attachments/assets/2de4f245-a2b7-4080-96c1-ff07bdb633aa)
![아키텍쳐](https://github.com/user-attachments/assets/bf9c1fff-3a84-43e5-aa87-092bb552a2d1)

---

## 7. 모델


### 7.1 페르소나별 세부 성능 비교

테스트 결과 및 해석

모델 성능 평가는 ROUGE-Lsum, BERT F1 Score, GPT Score, Time 네 가지 지표를 기준으로 진행되었다. LLaMA, SOLAR, EXAONE 등 주요 모델들과 비교했을 때, A.X는 일부 정량 지표에서 근소한 차이를 보였으나, 처리 속도(Time) 면에서 두드러진 성과를 보였다.

특히 EXAONE 모델이 각각 평균 10초, 15초대의 응답 시간을 기록한 반면, A.X는 대부분의 테스트에서 약 3초 내외의 응답 시간을 유지하였다. 이는 기존 모델 대비 최대 5배 이상 빠른 속도를 보여준 결과다.

속도의 우위는 단순한 기술적 효율성을 넘어, 서비스 경험에 직접적인 가치를 제공한다. 실시간 스트리밍 및 상담 서비스의 특성상, 지연 없는 즉각적 응답은 사용자 몰입도와 만족도를 크게 좌우한다. 따라서 A.X 모델의 빠른 응답 속도는 서비스 차별화의 핵심 경쟁력이라 할 수 있다.

결론적으로, A.X는 성능과 정확도에서 기존 모델들과 유사한 수준을 유지하면서도, 실시간 상호작용 환경에 최적화된 속도를 확보했다는 점에서 실질적 의미를 가진다. 이는 곧 상담 품질뿐 아니라 사용자 경험의 즉시성과 몰입도를 극대화할 수 있는 기반이 된다.


#### (1) 페르소나 1 왼쪽상단 

| 모델 | ROUGE-Lsum | BERT F1 | GPT Score | Time
|------|---------|---------|---------|--------|
| **A.X** | 0.0444 | 0.7101 | 3.17 | 3.98 |
| LLaMA | 0.0444 | 0.7101 | 3.17 | 5.92 |
| SOLAR | 0.0500  | 0.7005 | 2.80 | 28.58 |
| EXAONE | 0.0356 | 0.7243 | 3.30 | 15.06 |


#### (2) 페르소나 2 오른쪽 상단 

| 모델 | ROUGE-Lsum | BERT F1 | GPT Score | Time
|------|---------|---------|---------|--------|
| **A.X** | 0.0333 | 0.7003 | 3.73 | 2.97 |
| LLaMA | 0.0000 | 0.7016 | 2.00 | 2.93 |
| SOLAR | 0.0000  | 0.6990 | 2.07 | 8.42 |
| EXAONE | 0.0000 | 0.7035 | 2.13 | 11.13 |

#### (3) 페르소나 3 – 왼쪽 하단 

| 모델 | ROUGE-Lsum | BERT F1 | GPT Score | Time
|------|---------|---------|---------|--------|
| **A.X** | 0.0639 | 0.6707 | 2.70 | 3.92 |
| LLaMA | 0.0000 | 0.6236 | 1.03 | 1.65 |
| SOLAR | 0.0315  | 0.6985 | 2.07 | 13.70 |
| EXAONE | 0.0111 | 0.6470 | 1.20 | 10.10 |

#### (4) 페르소나 4 – 오른쪽 하단 

| 모델 | ROUGE-Lsum | BERT F1 | GPT Score | Time
|------|---------|---------|---------|--------|
| **A.X** | 0.0000 | 0.7183 | 2.00 | 2.72 |
| LLaMA | 0.0000 | 0.7108 | 2.07 | 2.58 |
| SOLAR | 0.0000  | 0.7121 | 2.13 | 7.25 |
| EXAONE | 0.0000 | 0.7200 | 3.17 | 10.35 |



---
## 8. Langchain vs 

04. 테스트 결과 – LangChain vs LangGraph

LangChain과 LangGraph를 동일 조건에서 비교한 결과, LangGraph는 모든 배치 크기에서 더 빠른 응답 속도를 기록했다.

소규모 배치(3개 메시지, 3회 반복): LangChain 11.72초 → LangGraph 9.35초

미디엄 배치(7개 메시지, 2회 반복): LangChain 27.57초 → LangGraph 20.50초

대규모 배치(15개 메시지, 1회 반복): LangChain 49.63초 → LangGraph 45.10초

실험 결과 LangGraph는 평균적으로 LangChain 대비 18.3%의 속도 개선을 달성했다. 이는 단순한 기술적 효율성 향상을 넘어, 실시간 스트리밍 서비스의 핵심 경쟁력인 즉각적인 응답성을 보장한다는 점에서 의미가 크다.

따라서 LangGraph는 대규모 사용자 환경에서도 안정적이면서 빠른 응답을 가능하게 하며, 서비스 확장성과 사용자 경험을 동시에 향상시키는 기반이 된다.





## 9. 서버 부하 테스트 



## 우리 홈페이지 사진들 넣기 





---

## 8. 역할 분담  

| 분야 | 담당자 |
|------|--------|
| AI(자연어) | 박현아, 장진슬 |
| AI(멀티모달) | 구재회 |
| Backend & Server | 모지호 |
| Frontend & Backend | 이재범 |

---

## 9. 참고 자료  
- [1] SBSNOW – AI 플러팅 스킬 사례  
- [2] 전자신문 – 생성형 AI 이용자 통계  
- [3] CBS News – 10대 AI 컴패니언 이용 현황  
