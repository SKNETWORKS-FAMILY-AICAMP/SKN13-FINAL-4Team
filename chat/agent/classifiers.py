# backend/chat/agent/classifiers.py
import re
import json
from .db import Utils
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

class LiteClassifier:
    """ê²½ëŸ‰ LLM 1íšŒ í˜¸ì¶œë¡œ ë¶„ë¥˜/ë¼ë²¨ë§ ìˆ˜í–‰"""
    def __init__(self, fast_llm: ChatOpenAI):
        self.fast_llm = fast_llm

    def _parse_or_default(self, raw: str) -> dict:
        m = re.search(r"\{{[\s\S]*\}}", raw or "")
        try:
            data = json.loads(m.group()) if m else {}
        except Exception:
            data = {}
        return {{
            "love": float(data.get("love", 0.0)),
            "greeting": float(data.get("greeting", 0.0)),
            "trivia": float(data.get("trivia", 0.0)),
            "topic": (data.get("topic") or "ì¼ë°˜")[:30],
            "group_key": (data.get("group_key") or data.get("topic") or "ì¼ë°˜")[:20],
            "salience": float(data.get("salience", 0.4)),
            "is_question": bool(data.get("is_question", False)),
        }}

    def classify(self, user_text: str) -> dict:
        sys = SystemMessage(content=(
            "ë„ˆëŠ” ì‹¤ì‹œê°„ ì±„íŒ…ì„ ë¹ ë¥´ê²Œ ë¶„ë¥˜/ë¼ë²¨ë§í•˜ëŠ” ë³´ì¡°ìžë‹¤.\n"
            "JSON í•˜ë‚˜ë§Œ ì¶œë ¥í•´ë¼. í‚¤: love, greeting, trivia (0~1), topic(ëª…ì‚¬êµ¬), group_key(4~12ìž), salience(0~2.5ê¶Œìž¥), is_question(bool)."
        ))
        prompt = HumanMessage(content=f"ë¬¸ìž¥: \"{user_text}\"\nJSONë§Œ ì¶œë ¥")
        try:
            r = self.fast_llm.invoke([sys, prompt])
            return self._parse_or_default(getattr(r, "content", str(r)))
        except Exception:
            low = (user_text or "").lower()
        if any(k in low for k in ["ê³ ë°±","ì§ì‚¬ëž‘","ì´ë³„","ì—°ì• ","ì¸"]):
            return {"love":0.8,"greeting":0.1,"trivia":0.1,"topic":"ì—°ì•  ê³ ë¯¼","group_key":"ì—°ì•  ê³ ë¯¼","salience":0.8,"is_question":"?" in low}
        if any(k in low for k in ["ì•ˆë…•","í•˜ì´","ë°˜ê°€","ì¶œì²µ"]):
            return {"love":0.1,"greeting":0.7,"trivia":0.2,"topic":"ì¸ì‚¬","group_key":"ì¸ì‚¬","salience":0.3,"is_question":False}
        return {"love":0.2,"greeting":0.1,"trivia":0.7,"topic":"ì¼ë°˜","group_key":"ì¼ë°˜","salience":0.2,"is_question":"?" in low}

    @staticmethod
    def map_intent_to_categories(intent: dict, threshold: float = 0.3) -> list:
        cats = []
        order = [("love","ì—°ì• "),("greeting","ì¸ì‚¬"),("trivia","ê¸°íƒ€")]
        for k, cat in order:
            if intent.get(k, 0.0) >= threshold:
                cats.append(cat)
        if intent.get("love",0.0) >= 0.7 and intent.get("greeting",0.0) >= 0.15 and "ì¸ì‚¬" not in cats:
            cats.append("ì¸ì‚¬")
        return cats or ["ê¸°íƒ€"]

class EmotionClassifier:
    """HuggingFace ê¸°ë°˜ í•œêµ­ì–´ ê°ì • ë¶„ë¥˜ê¸°"""
    LABELS = ("neutral", "happy", "sad", "mad")

    def __init__(self, fast_llm: ChatOpenAI = None):
        # fast_llmì€ í˜¸í™˜ì„±ì„ ìœ„í•´ ë°›ì§€ë§Œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        self.model = None
        self.tokenizer = None
        self.fast_llm = fast_llm
        
        try:
            from transformers import AutoModelForSequenceClassification, AutoTokenizer
            import torch
            
            # ëª¨ë¸ ê°œë°œìž í…ŒìŠ¤íŠ¸ ì½”ë“œ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •
            tokenizer_name = "monologg/kobert"
            model_name = "rkdaldus/ko-sent5-classification"
            
            print(f"ðŸ”„ í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹œë„: {tokenizer_name}")
            self.tokenizer = AutoTokenizer.from_pretrained(
                tokenizer_name,
                trust_remote_code=True
            )
            
            print(f"ðŸ”„ ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì‹œë„: {model_name}")
            self.model = AutoModelForSequenceClassification.from_pretrained(
                model_name,
                trust_remote_code=True
            )
            
            # ì¸ë±ìŠ¤ì—ì„œ ì‹œìŠ¤í…œ ë¼ë²¨ë¡œ ì§ì ‘ ë§¤í•‘
            # 0: Angry, 1: Fear, 2: Happy, 3: Tender, 4: Sad
            self.index_to_system_label = {
                0: "mad",      # Angry
                1: "sad",      # Fear  
                2: "happy",    # Happy
                3: "neutral",  # Tender
                4: "sad"       # Sad
            }
            
            print(f"âœ… HuggingFace ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
            
        except ImportError as e:
            print(f"âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í•„ìš”: {e}")
            print("ðŸ“¦ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
            print("   pip install transformers torch protobuf")
            print("ðŸ”„ ë£° ê¸°ë°˜ í´ë°± ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âŒ HuggingFace ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ðŸ”„ ë£° ê¸°ë°˜ í´ë°± ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            
        # ìµœì¢… ìƒíƒœ í™•ì¸
        if self.model is None or self.tokenizer is None:
            print("âš ï¸ HF ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€: ë£° ê¸°ë°˜ ë¶„ë¥˜ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")

    def classify(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ë¥˜í•˜ì—¬ ë¼ë²¨ ë°˜í™˜"""
        if self.model is None or self.tokenizer is None:
            # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë£° ê¸°ë°˜ í´ë°±
            return self._fallback_classify(text)
        
        try:
            # ê°œë°œìž í…ŒìŠ¤íŠ¸ ì½”ë“œ ë°©ì‹ìœ¼ë¡œ ì¶”ë¡ 
            import torch
            inputs = self.tokenizer(
                text, 
                return_tensors="pt", 
                padding=True, 
                truncation=True
            )
            
            with torch.no_grad():
                outputs = self.model(**inputs)
            
            # ê°€ìž¥ ë†’ì€ í™•ë¥ ì˜ ë¼ë²¨ ì¸ë±ìŠ¤ ì„ íƒ
            predicted_index = torch.argmax(outputs.logits, dim=1).item()
            
            # ì¸ë±ìŠ¤ì—ì„œ ì‹œìŠ¤í…œ ë¼ë²¨ë¡œ ì§ì ‘ ë§¤í•‘
            system_label = self.index_to_system_label.get(predicted_index, "neutral")
            
            return system_label
            
        except Exception as e:
            print(f"âš ï¸ HF ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}, í´ë°± ëª¨ë“œ ì‚¬ìš©")
            return self._fallback_classify(text)
    
    def _fallback_classify(self, text: str) -> str:
        """ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë£° ê¸°ë°˜ ë¶„ë¥˜"""
        try:
            low = (text or "").lower()
            if any(k in low for k in ["ê¸°ë»", "í–‰ë³µ", "ì¢‹ì•„", "ê³ ë§ˆì›Œ", "ê°ì‚¬", "yay", "great", "awesome", "ðŸ˜Š", "ðŸ˜€"]):
                return "happy"
            if any(k in low for k in ["ìŠ¬í¼", "ìš°ìš¸", "ì†ìƒ", "ëˆˆë¬¼", "íž˜ë“¤", "ã… ", "ã…œ", "sad", "depressed"]):
                return "sad"
            if any(k in low for k in ["í™”ë‚˜", "ë¹¡", "ì§œì¦", "ë¶„ë…¸", "ì—´ë°›", "angry", "mad", "furious", ">:("]):
                return "mad"
            return "neutral"
        except Exception:
            return "neutral"
