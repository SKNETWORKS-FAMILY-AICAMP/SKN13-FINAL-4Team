"""
ìŠ¤íŠ¸ë¦¬ë° ë„ë©”ì¸ ëª¨ë¸
DDD ì•„í‚¤í…ì²˜ ê¸°ë°˜ StreamSession, MediaPacket, MediaTrack êµ¬í˜„
Queue ê¸°ë°˜ ìˆœì°¨ ì²˜ë¦¬ ì‹œìŠ¤í…œ í¬í•¨
"""
from dataclasses import dataclass, field
import hashlib
import time
import asyncio
import logging
import weakref
from typing import Literal, Optional, Dict, Any, List, AsyncGenerator
from concurrent.futures import TimeoutError
from dataclasses import field as dataclass_field
import uuid

logger = logging.getLogger(__name__)

def now_ms() -> int:
    """í˜„ì¬ ì‹œê°„ì„ ë°€ë¦¬ì´ˆë¡œ ë°˜í™˜"""
    return int(time.perf_counter() * 1000)

@dataclass(frozen=True)
class MediaTrack:
    """ë¯¸ë””ì–´ íŠ¸ë™ ê°’ ê°ì²´"""
    kind: Literal["audio", "video", "subtitle"]
    pts_ms: int  # Presentation Time Stamp (ìƒëŒ€ì  ì‹œê°„, ms)
    dur_ms: int  # Duration (ì§€ì† ì‹œê°„, ms)
    payload_ref: str  # ë¯¸ë””ì–´ ë°ì´í„° ì°¸ì¡° (URL ë˜ëŠ” ë°ì´í„°)
    codec: str  # ì½”ë± ì •ë³´
    meta: Optional[Dict[str, Any]] = None  # ë©”íƒ€ë°ì´í„°
    
    def __post_init__(self):
        """ìœ íš¨ì„± ê²€ì‚¬"""
        if self.pts_ms < 0:
            raise ValueError(f"Invalid pts_ms: {self.pts_ms} (must be >= 0)")
        if self.dur_ms <= 0:
            raise ValueError(f"Invalid dur_ms: {self.dur_ms} (must be > 0)")
        if not self.payload_ref:
            raise ValueError("payload_ref cannot be empty")
        if not self.codec:
            raise ValueError("codec cannot be empty")

@dataclass(frozen=True)
class MediaPacket:
    """ë¯¸ë””ì–´ íŒ¨í‚· ê°’ ê°ì²´"""
    v: int  # ë²„ì „
    session_id: str  # ì„¸ì…˜ ID
    seq: int  # ì‹œí€€ìŠ¤ ë²ˆí˜¸
    t0_ms: int  # ì„¸ì…˜ ì‹œì‘ ì‹œì  (monotonic time ms)
    tracks: List[MediaTrack]  # íŠ¸ë™ ëª©ë¡
    hash: str  # íŒ¨í‚· í•´ì‹œ (ë¬´ê²°ì„± ê²€ì¦ìš©)
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (WebSocket ì „ì†¡ìš©)"""
        return {
            "v": self.v,
            "session_id": self.session_id,
            "seq": self.seq,
            "t0": self.t0_ms,
            "tracks": [
                {
                    "kind": track.kind,
                    "pts": track.pts_ms,
                    "dur": track.dur_ms,
                    "payload_ref": track.payload_ref,
                    "codec": track.codec,
                    "meta": track.meta or {}
                }
                for track in self.tracks
            ],
            "hash": self.hash
        }

class StreamSession:
    """ìŠ¤íŠ¸ë¦¬ë° ì„¸ì…˜ ì• ê·¸ë¦¬ê²Œì´íŠ¸ ë£¨íŠ¸ - Queue ê¸°ë°˜ ìˆœì°¨ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, session_id: Optional[str] = None):
        self.session_id = session_id or uuid.uuid4().hex
        self.t0_ms = now_ms()  # ì„¸ì…˜ ì‹œì‘ ì‹œì 
        self.seq = 0  # ì‹œí€€ìŠ¤ ë²ˆí˜¸
        self._recent_hashes: List[str] = []  # ì¤‘ë³µ íŒ¨í‚· ë°©ì§€ìš© (ìµœê·¼ 50ê°œ ì €ì¥)
        
        # ğŸ†• Request Queue - MediaPacket ìƒì„±ìš©
        self.request_queue = asyncio.Queue(maxsize=50)  # ìš”ì²­ ëŒ€ê¸°ì—´ (í¬ê¸° ì œí•œ)
        self.processing_lock = asyncio.Lock()  # ë™ì‹œ ì²˜ë¦¬ ë°©ì§€
        self.current_processing: Optional[Dict[str, Any]] = None  # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ìš”ì²­
        self.is_processing = False  # ì²˜ë¦¬ ìƒíƒœ í”Œë˜ê·¸
        self.processing_timeout = 30.0  # ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        
        # ğŸ†• Response Queue - MediaPacket ì¬ìƒìš© (ì™„ì „ ë…ë¦½)
        self.response_queue = asyncio.Queue(maxsize=30)  # ì¬ìƒ ëŒ€ê¸°ì—´ (í¬ê¸° ì œí•œ)
        self.playback_lock = asyncio.Lock()  # ì¬ìƒ ë™ì‹œ ë°©ì§€
        self.current_playing: Optional[MediaPacket] = None  # í˜„ì¬ ì¬ìƒ ì¤‘ì¸ íŒ¨í‚·
        self.is_playing = False  # ì¬ìƒ ìƒíƒœ í”Œë˜ê·¸
        self.playback_start_time: Optional[int] = None  # ì¬ìƒ ì‹œì‘ ì‹œê°„
        self.playback_timeout = 60.0  # ì¬ìƒ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        
        # ğŸ†• ì·¨ì†Œ ë° ì—ëŸ¬ ë³µêµ¬
        self.cancellation_events: Dict[str, asyncio.Event] = {}  # ìš”ì²­ë³„ ì·¨ì†Œ ì´ë²¤íŠ¸
        self.retry_count = 0  # ì¬ì‹œë„ íšŸìˆ˜
        self.max_retries = 3  # ìµœëŒ€ ì¬ì‹œë„
        self.failed_requests: List[Dict[str, Any]] = []  # ì‹¤íŒ¨í•œ ìš”ì²­ë“¤ (ìµœê·¼ 10ê°œ)
        
        # ğŸ†• Queue ë©”íŠ¸ë¦­ ë° ìƒíƒœ ì¶”ì 
        self.total_processed = 0  # ì´ ì²˜ë¦¬ëœ ìš”ì²­ ìˆ˜
        self.cancelled_requests = 0  # ì·¨ì†Œëœ ìš”ì²­ ìˆ˜
        self.processing_times = []  # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡ (ìµœê·¼ 10ê°œ)
        self.max_queue_length = 0  # ìµœëŒ€ í ê¸¸ì´ ê¸°ë¡
        self.recent_history = []  # ìµœê·¼ ì²˜ë¦¬ ì´ë ¥ (ìµœê·¼ 10ê°œ)
        
        # ğŸ†• Response Queue ë©”íŠ¸ë¦­
        self.total_played = 0  # ì´ ì¬ìƒëœ íŒ¨í‚· ìˆ˜
        self.playback_history = []  # ì¬ìƒ ì´ë ¥ (ìµœê·¼ 10ê°œ)
        
        # ğŸ†• ë©”ëª¨ë¦¬ ê´€ë¦¬ìš© ì•½í•œ ì°¸ì¡°
        self._queue_snapshot_cache = weakref.WeakValueDictionary()
        
    def build_packet(self, tracks: List[MediaTrack]) -> MediaPacket:
        """
        ë¯¸ë””ì–´ íŒ¨í‚· ìƒì„±
        
        Args:
            tracks: ë¯¸ë””ì–´ íŠ¸ë™ ëª©ë¡
            
        Returns:
            MediaPacket: ìƒì„±ëœ ë¯¸ë””ì–´ íŒ¨í‚·
            
        Raises:
            ValueError: íŠ¸ë™ì´ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
        """
        if not tracks:
            raise ValueError("No tracks provided")
        
        # íŠ¸ë™ ìœ íš¨ì„± ê²€ì‚¬ëŠ” MediaTrack.__post_init__ì—ì„œ ì²˜ë¦¬
        
        # íŒ¨í‚· í•´ì‹œ ìƒì„± (íŠ¸ë™ ë‚´ìš© + ì‹œí€€ìŠ¤ + íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)
        current_time = now_ms()
        raw_content = "|".join(
            f"{t.kind}:{t.pts_ms}:{t.dur_ms}:{t.payload_ref}:{t.codec}"
            for t in tracks
        )
        # ì‹œí€€ìŠ¤ ë²ˆí˜¸ì™€ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
        unique_content = f"{self.seq}:{current_time}:{raw_content}"
        packet_hash = hashlib.sha256(unique_content.encode()).hexdigest()[:16]  # 16ìë¦¬ë¡œ ë‹¨ì¶•
        
        # ì¤‘ë³µ íŒ¨í‚· ì²´í¬
        if packet_hash in self._recent_hashes:
            raise ValueError(f"Duplicate packet detected: {packet_hash}")
        
        # ìµœê·¼ í•´ì‹œ ëª©ë¡ ê´€ë¦¬ (ìµœëŒ€ 50ê°œ)
        self._recent_hashes.append(packet_hash)
        if len(self._recent_hashes) > 50:
            self._recent_hashes = self._recent_hashes[-50:]
        
        # íŒ¨í‚· ìƒì„±
        packet = MediaPacket(
            v=1,  # ë²„ì „ 1
            session_id=self.session_id,
            seq=self.seq,
            t0_ms=self.t0_ms,
            tracks=tracks,
            hash=packet_hash
        )
        
        # ì‹œí€€ìŠ¤ ë²ˆí˜¸ ì¦ê°€
        self.seq += 1
        
        return packet
    
    def create_audio_track(self, audio_data_url: str, duration_ms: int, 
                          emotion: str = "neutral", voice: str = "default") -> MediaTrack:
        """ì˜¤ë””ì˜¤ íŠ¸ë™ ìƒì„± í—¬í¼"""
        return MediaTrack(
            kind="audio",
            pts_ms=0,  # ì¦‰ì‹œ ì‹œì‘
            dur_ms=duration_ms,
            payload_ref=audio_data_url,
            codec="audio/mpeg",
            meta={
                "emotion": emotion,
                "voice": voice
            }
        )
    
    def create_video_track(self, video_path: str, duration_ms: int, 
                          clip_type: str = "talk") -> MediaTrack:
        """ë¹„ë””ì˜¤ íŠ¸ë™ ìƒì„± í—¬í¼"""
        return MediaTrack(
            kind="video",
            pts_ms=0,  # ì¦‰ì‹œ ì‹œì‘
            dur_ms=duration_ms,
            payload_ref=video_path,
            codec="video/mp4",
            meta={
                "clip_type": clip_type
            }
        )
    
    def create_subtitle_track(self, subtitle_data: Dict[str, Any], 
                            duration_ms: int) -> MediaTrack:
        """ìë§‰ íŠ¸ë™ ìƒì„± í—¬í¼"""
        return MediaTrack(
            kind="subtitle",
            pts_ms=0,  # ì¦‰ì‹œ ì‹œì‘
            dur_ms=duration_ms,
            payload_ref=str(subtitle_data),  # JSON ë¬¸ìì—´ë¡œ ì €ì¥
            codec="text/json",
            meta=subtitle_data
        )
    
    async def enqueue_request(self, request_data: Dict[str, Any], timeout: float = 5.0) -> bool:
        """
        ìš”ì²­ì„ íì— ì¶”ê°€ - íƒ€ì„ì•„ì›ƒ ë° ìš°ì„ ìˆœìœ„ ì§€ì›
        
        Args:
            request_data: ì²˜ë¦¬í•  ìš”ì²­ ë°ì´í„° (message, user_id, streamer_config ë“±)
            timeout: í ì¶”ê°€ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ìš”ì²­ ID ìƒì„± ë° ì·¨ì†Œ ì´ë²¤íŠ¸ ë“±ë¡
            request_id = uuid.uuid4().hex
            request_data['request_id'] = request_id
            request_data['enqueued_at'] = now_ms()
            
            self.cancellation_events[request_id] = asyncio.Event()
            
            # í í¬í™” ìƒíƒœ ì²´í¬
            if self.request_queue.qsize() >= 40:  # 80% í¬í™”ì‹œ ê²½ê³ 
                logger.warning(f"âš ï¸ Request Queue í¬í™” ìƒíƒœ: {self.request_queue.qsize()}/50")
                
            # íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ íì— ì¶”ê°€
            await asyncio.wait_for(self.request_queue.put(request_data), timeout=timeout)
            queue_size = self.request_queue.qsize()
            
            logger.info(f"ğŸ“ [QUEUE] ìš”ì²­ ì¶”ê°€: '{request_data.get('message', '')[:30]}...' | í í¬ê¸°: {queue_size} | ì‚¬ìš©ì: {request_data.get('username', 'Unknown')} | ID: {request_id[:8]}")
            return True
            
        except asyncio.TimeoutError:
            logger.error(f"âŒ Request Queue ì¶”ê°€ íƒ€ì„ì•„ì›ƒ: {request_data.get('message', '')[:30]}...")
            return False
        except Exception as e:
            logger.error(f"âŒ Request Queue ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    async def enqueue_response(self, media_packet: MediaPacket, timeout: float = 3.0) -> bool:
        """
        MediaPacketì„ Response Queueì— ì¶”ê°€ (ì¬ìƒ ëŒ€ê¸°ì—´)
        
        Args:
            media_packet: ì¬ìƒí•  MediaPacket
            timeout: í ì¶”ê°€ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            # í í¬í™” ìƒíƒœ ì²´í¬
            if self.response_queue.qsize() >= 25:  # 83% í¬í™”ì‹œ ê²½ê³ 
                logger.warning(f"âš ï¸ Response Queue í¬í™” ìƒíƒœ: {self.response_queue.qsize()}/30")
            
            await asyncio.wait_for(self.response_queue.put(media_packet), timeout=timeout)
            logger.info(f"ğŸ“¤ Response Queueì— ì¶”ê°€: seq={media_packet.seq}, hash={media_packet.hash[:8]} (ì¬ìƒ í í¬ê¸°: {self.response_queue.qsize()})")
            return True
            
        except asyncio.TimeoutError:
            logger.error(f"âŒ Response Queue ì¶”ê°€ íƒ€ì„ì•„ì›ƒ: seq={media_packet.seq}")
            return False
        except Exception as e:
            logger.error(f"âŒ Response Queue ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    async def process_response_queue(self) -> AsyncGenerator[MediaPacket, None]:
        """
        Response Queueë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ MediaPacket ì¬ìƒ
        
        Yields:
            MediaPacket: ì¬ìƒí•  ë¯¸ë””ì–´ íŒ¨í‚· (ë¸Œë¡œë“œìºìŠ¤íŠ¸ìš©)
        """
        logger.info(f"ğŸµ Response Queue Processor ì‹œì‘: {self.session_id[:8]}")
        
        while True:
            try:
                # ë‹¤ìŒ MediaPacket ëŒ€ê¸° (ì¬ìƒ ì™„ë£Œ ëŒ€ê¸° ì œê±°)
                media_packet = await self.response_queue.get()
                
                # ì¬ìƒ ì‹œì‘ (lock ì—†ì´ ê°„ë‹¨í•˜ê²Œ)
                self.current_playing = media_packet
                self.playback_start_time = now_ms()
                
                logger.info(f"ğŸ¬ ì—°ì† ì¬ìƒ: seq={media_packet.seq}, hash={media_packet.hash[:8]} (ëŒ€ê¸°ì—´: {self.response_queue.qsize()})")
                
                # ì¬ìƒ ì´ë ¥ ì—…ë°ì´íŠ¸
                playback_item = {
                    "timestamp": now_ms(),
                    "seq": media_packet.seq,
                    "hash": media_packet.hash[:8],
                    "tracks_count": len(media_packet.tracks),
                    "status": "playing"
                }
                self.playback_history.insert(0, playback_item)
                if len(self.playback_history) > 10:
                    self.playback_history.pop()
                
                # MediaPacket ë¸Œë¡œë“œìºìŠ¤íŠ¸ë¥¼ ìœ„í•´ yield
                yield media_packet
                
                # ì¦‰ì‹œ ë‹¤ìŒ íŒ¨í‚· ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
                self.response_queue.task_done()
                    
            except asyncio.CancelledError:
                logger.info(f"ğŸš« Response Queue Processor ì·¨ì†Œë¨: {self.session_id[:8]}")
                break
            except Exception as e:
                logger.error(f"âŒ Response Queue ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    def mark_playback_completed(self, seq: int):
        """
        ì¬ìƒ ì™„ë£Œ í‘œì‹œ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í˜¸ì¶œ)
        
        Args:
            seq: ì™„ë£Œëœ MediaPacketì˜ ì‹œí€€ìŠ¤ ë²ˆí˜¸
        """
        if self.current_playing and self.current_playing.seq == seq:
            playback_time = (now_ms() - self.playback_start_time) / 1000.0 if self.playback_start_time else 0
            
            logger.info(f"âœ… ì¬ìƒ ì™„ë£Œ: seq={seq}, ì¬ìƒì‹œê°„={playback_time:.1f}ì´ˆ")
            
            # ì¬ìƒ ì™„ë£Œ ì´ë ¥ ì—…ë°ì´íŠ¸
            if self.playback_history and self.playback_history[0]["seq"] == seq:
                self.playback_history[0]["status"] = "completed"
                self.playback_history[0]["playback_time"] = playback_time
            
            # ìƒíƒœ ë¦¬ì…‹
            self.current_playing = None
            self.is_playing = False
            self.playback_start_time = None
            self.total_played += 1
        else:
            logger.warning(f"âš ï¸ ì¬ìƒ ì™„ë£Œ ì‹ í˜¸ ë¶ˆì¼ì¹˜: í˜„ì¬={self.current_playing.seq if self.current_playing else None}, ìš”ì²­={seq}")
    
    async def process_queue(self, media_processor) -> None:
        """
        íë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ MediaPacket ìƒì„± (ì·¨ì†Œ ê°€ëŠ¥í•œ ì²˜ë¦¬)
        
        Args:
            media_processor: MediaProcessingHub ì¸ìŠ¤í„´ìŠ¤
        """
        while True:
            try:
                # ë‹¤ìŒ ìš”ì²­ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ í¬í•¨)
                request_data = await asyncio.wait_for(
                    self.request_queue.get(), 
                    timeout=self.processing_timeout
                )
                
                request_id = request_data.get('request_id', 'unknown')
                
                async with self.processing_lock:
                    # ì·¨ì†Œ í™•ì¸
                    if request_id in self.cancellation_events:
                        if self.cancellation_events[request_id].is_set():
                            logger.info(f"ğŸš« ì·¨ì†Œëœ ìš”ì²­ ê±´ë„ˆë›°ê¸°: {request_id[:8]}")
                            self._update_processing_metrics(0, 'cancelled')
                            self.request_queue.task_done()
                            continue
                    
                    # ì²˜ë¦¬ ì‹œì‘
                    start_time = now_ms()
                    request_data['start_time'] = start_time
                    self.current_processing = request_data
                    self.is_processing = True
                    
                    logger.info(f"ğŸ¬ ìš”ì²­ ì²˜ë¦¬ ì‹œì‘: {request_data.get('message', '')[:30]}... (ID: {request_id[:8]}, seq: {self.seq})")
                    
                    try:
                        # ì·¨ì†Œ ê°€ëŠ¥í•œ MediaTrack ìƒì„± (íƒ€ì„ì•„ì›ƒ í¬í•¨)
                        cancellation_event = self.cancellation_events.get(request_id)
                        
                        tracks = await asyncio.wait_for(
                            media_processor.generate_tracks_with_cancellation(
                                request_data, cancellation_event
                            ),
                            timeout=self.processing_timeout
                        )
                        
                        # ì·¨ì†Œ ì¬í™•ì¸
                        if cancellation_event and cancellation_event.is_set():
                            logger.info(f"ğŸš« ì²˜ë¦¬ ì¤‘ ì·¨ì†Œë¨: {request_id[:8]}")
                            self._update_processing_metrics(
                                (now_ms() - start_time) / 1000.0, 'cancelled'
                            )
                        elif tracks:
                            # ì„±ê³µ ì²˜ë¦¬
                            processing_time = (now_ms() - start_time) / 1000.0
                            media_packet = self.build_packet(tracks)
                            
                            # Response Queueì— ì¶”ê°€ (íƒ€ì„ì•„ì›ƒ í¬í•¨)
                            success = await self.enqueue_response(media_packet, timeout=3.0)
                            if success:
                                self._update_processing_metrics(processing_time, 'completed')
                                logger.info(f"âœ… MediaPacket ìƒì„± ì™„ë£Œ: {media_packet.hash[:8]} (seq: {media_packet.seq})")
                            else:
                                self._update_processing_metrics(processing_time, 'failed')
                                logger.error(f"âŒ Response Queue ì¶”ê°€ ì‹¤íŒ¨: {media_packet.hash[:8]}")
                        else:
                            # ì‹¤íŒ¨ ì²˜ë¦¬
                            processing_time = (now_ms() - start_time) / 1000.0
                            self._update_processing_metrics(processing_time, 'failed')
                            
                            # ì‹¤íŒ¨í•œ ìš”ì²­ì„ ì‹¤íŒ¨ ëª©ë¡ì— ì¶”ê°€
                            self._add_failed_request(request_data, "íŠ¸ë™ ìƒì„± ì‹¤íŒ¨")
                            
                    except asyncio.TimeoutError:
                        processing_time = (now_ms() - start_time) / 1000.0
                        self._update_processing_metrics(processing_time, 'timeout')
                        self._add_failed_request(request_data, f"ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ ({self.processing_timeout}ì´ˆ)")
                        logger.error(f"â° ìš”ì²­ ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ: {request_id[:8]}")
                        
                    except Exception as e:
                        processing_time = (now_ms() - start_time) / 1000.0
                        self._update_processing_metrics(processing_time, 'failed')
                        self._add_failed_request(request_data, str(e))
                        logger.error(f"âŒ ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {request_id[:8]} - {e}")
                        
                    finally:
                        # ì •ë¦¬ ì‘ì—…
                        self.current_processing = None
                        self.is_processing = False
                        self.request_queue.task_done()
                        
                        # ì·¨ì†Œ ì´ë²¤íŠ¸ ì •ë¦¬
                        if request_id in self.cancellation_events:
                            self.cancellation_events.pop(request_id, None)
                        
                        # ì£¼ê¸°ì  ì •ë¦¬ (100ê°œ ìš”ì²­ë§ˆë‹¤)
                        if self.total_processed % 100 == 0:
                            await self.cleanup_cancelled_events()
                            
            except asyncio.TimeoutError:
                logger.debug("Queue ì²˜ë¦¬ ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ (ì •ìƒ ë™ì‘)")
                continue
            except Exception as e:
                logger.error(f"âŒ Queue ì²˜ë¦¬ ì‹¬ê°í•œ ì˜¤ë¥˜: {str(e)}")
                await asyncio.sleep(1)  # ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
    
    def get_session_info(self) -> Dict[str, Any]:
        """ì„¸ì…˜ ì •ë³´ ë°˜í™˜ (Queue ìƒíƒœ í¬í•¨)"""
        return {
            "session_id": self.session_id,
            "t0_ms": self.t0_ms,
            "current_seq": self.seq,
            "uptime_ms": now_ms() - self.t0_ms,
            "recent_hashes_count": len(self._recent_hashes),
            # ğŸ†• Queue ìƒíƒœ ì •ë³´
            "queue_length": self.request_queue.qsize(),
            "is_processing": self.is_processing,
            "current_request": self.current_processing.get('message', '')[:30] if self.current_processing else None
        }
    
    async def get_detailed_queue_info(self) -> Dict[str, Any]:
        """
        ìƒì„¸í•œ Queue ìƒíƒœ ì •ë³´ ë°˜í™˜ (Debug Panelìš©)
        
        Returns:
            Dict containing detailed queue information for debugging
        """
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        avg_processing_time = (
            sum(self.processing_times) / len(self.processing_times) 
            if self.processing_times else 0
        )
        
        # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ìš”ì²­ ì •ë³´
        current_processing_info = None
        if self.current_processing:
            processing_duration = (
                (now_ms() - self.current_processing.get('start_time', 0)) / 1000
                if self.current_processing.get('start_time') else 0
            )
            current_processing_info = {
                "message": self.current_processing.get('message', ''),
                "username": self.current_processing.get('username', 'unknown'),
                "user_id": self.current_processing.get('user_id'),
                "start_time": self.current_processing.get('start_time'),
                "processing_duration": processing_duration,
                "room_group": self.current_processing.get('room_group')
            }
        
        # ğŸ†• Request Queue ëŒ€ê¸° ìš”ì²­ë“¤ ì •ë³´ (ì•ˆì „í•œ peek ë°©ì‹)
        pending_requests = await self._safe_peek_request_queue()
        
        # ğŸ†• Response Queue ëŒ€ê¸° MediaPacketë“¤ ì •ë³´ (ì•ˆì „í•œ peek ë°©ì‹)
        pending_media_packets = await self._safe_peek_response_queue()
        
        return {
            "session_id": self.session_id,
            "timestamp": now_ms(),
            
            # ğŸ†• Request Queue ìƒíƒœ
            "request_queue": {
                "length": self.request_queue.qsize(),
                "is_processing": self.is_processing,
                "current_processing": current_processing_info,
                "pending_requests": pending_requests,
            },
            
            # ğŸ†• Response Queue ìƒíƒœ
            "response_queue": {
                "length": self.response_queue.qsize(),
                "is_playing": self.is_playing,
                "current_playing": {
                    "seq": self.current_playing.seq if self.current_playing else None,
                    "hash": self.current_playing.hash[:8] if self.current_playing else None,
                    "tracks": len(self.current_playing.tracks) if self.current_playing else 0
                } if self.current_playing else None,
                "pending_packets": pending_media_packets,
                "total_played": self.total_played
            },
            
            # ê¸°ë³¸ ìƒíƒœ (í˜¸í™˜ì„±)
            "queue_length": self.request_queue.qsize(),
            "is_processing": self.is_processing,
            "current_seq": self.seq,
            "uptime_ms": now_ms() - self.t0_ms,
            
            # ë©”íŠ¸ë¦­ (í™•ì¥)
            "metrics": {
                "total_processed": self.total_processed,
                "cancelled_requests": self.cancelled_requests,
                "failed_requests_count": len(self.failed_requests),
                "avg_processing_time": avg_processing_time,
                "max_queue_length": self.max_queue_length,
                "recent_processing_times": self.processing_times.copy(),
                "recent_hashes_count": len(self._recent_hashes),
                "active_cancellation_events": len(self.cancellation_events),
                "processing_timeout": self.processing_timeout,
                "playback_timeout": self.playback_timeout
            },
            
            # ì‹¤íŒ¨ ìš”ì²­ ëª©ë¡
            "failed_requests": self.failed_requests.copy(),
            
            # ìµœê·¼ ì²˜ë¦¬ ì´ë ¥
            "recent_history": self.recent_history.copy(),
            
            # ì‹œìŠ¤í…œ ìƒíƒœ
            "system_health": {
                "request_queue_utilization": (self.request_queue.qsize() / 50.0) * 100,
                "response_queue_utilization": (self.response_queue.qsize() / 30.0) * 100,
                "avg_success_rate": ((self.total_processed - self.cancelled_requests - len(self.failed_requests)) / max(self.total_processed, 1)) * 100,
                "memory_pressure": len(self.cancellation_events) > 100
            }
        }
    
    def _update_processing_metrics(self, processing_time: float, status: str = 'completed'):
        """ì²˜ë¦¬ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        if status == 'completed':
            self.total_processed += 1
            
            # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡ (ìµœê·¼ 10ê°œë§Œ ìœ ì§€)
            self.processing_times.append(processing_time)
            if len(self.processing_times) > 10:
                self.processing_times.pop(0)
                
        elif status in ['cancelled', 'timeout']:
            self.cancelled_requests += 1
            
        elif status == 'failed':
            # ì‹¤íŒ¨í•œ ìš”ì²­ë„ ì´ ì²˜ë¦¬ ìˆ˜ì— í¬í•¨
            self.total_processed += 1
        
        # ìµœëŒ€ í ê¸¸ì´ ì—…ë°ì´íŠ¸
        current_queue_length = self.request_queue.qsize()
        if current_queue_length > self.max_queue_length:
            self.max_queue_length = current_queue_length
        
        # ìµœê·¼ ì´ë ¥ ì—…ë°ì´íŠ¸ (ìµœê·¼ 10ê°œë§Œ ìœ ì§€)
        history_item = {
            "timestamp": now_ms(),
            "message": self.current_processing.get('message', '')[:30] if self.current_processing else '',
            "username": self.current_processing.get('username', 'unknown') if self.current_processing else '',
            "request_id": self.current_processing.get('request_id', 'unknown')[:8] if self.current_processing else '',
            "status": status,
            "processing_time": processing_time,
            "seq": self.seq - 1 if status == 'completed' else None
        }
        
        self.recent_history.insert(0, history_item)
        if len(self.recent_history) > 10:
            self.recent_history.pop()
        
        logger.info(f"ğŸ“Š ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸: {status}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ, íí¬ê¸°: {current_queue_length}, ì´ì²˜ë¦¬: {self.total_processed}")
    
    def _add_failed_request(self, request_data: Dict[str, Any], error_msg: str):
        """ì‹¤íŒ¨í•œ ìš”ì²­ì„ ê¸°ë¡"""
        failed_item = {
            "timestamp": now_ms(),
            "request_id": request_data.get('request_id', 'unknown')[:8],
            "message": request_data.get('message', '')[:50],
            "username": request_data.get('username', 'unknown'),
            "error": error_msg,
            "retry_count": request_data.get('retry_count', 0)
        }
        
        self.failed_requests.insert(0, failed_item)
        if len(self.failed_requests) > 10:
            self.failed_requests.pop()
            
        logger.warning(f"âŒ ì‹¤íŒ¨ ìš”ì²­ ê¸°ë¡: {failed_item['request_id']} - {error_msg}")
    
    async def cancel_request(self, request_id: str) -> bool:
        """
        íŠ¹ì • ìš”ì²­ ì·¨ì†Œ
        
        Args:
            request_id: ì·¨ì†Œí•  ìš”ì²­ ID
            
        Returns:
            bool: ì·¨ì†Œ ì„±ê³µ ì—¬ë¶€
        """
        if request_id in self.cancellation_events:
            self.cancellation_events[request_id].set()
            logger.info(f"ğŸš« ìš”ì²­ ì·¨ì†Œ ì‹ í˜¸ ì „ì†¡: {request_id[:8]}")
            return True
        return False
    
    async def _safe_peek_request_queue(self, max_items: int = 10) -> List[Dict[str, Any]]:
        """
        Request Queueì˜ ë‚´ìš©ì„ ì•ˆì „í•˜ê²Œ ì¡°íšŒ (Queue ìˆœì„œ ë³´ì¡´)
        
        Args:
            max_items: ìµœëŒ€ ì¡°íšŒí•  ì•„ì´í…œ ìˆ˜
            
        Returns:
            List[Dict]: ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì •ë³´
        """
        if self.request_queue.qsize() == 0:
            return []
            
        pending_requests = []
        temp_items = []
        
        try:
            # íì—ì„œ ì•„ì´í…œë“¤ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ (ìµœëŒ€ max_itemsê°œ)
            items_to_extract = min(self.request_queue.qsize(), max_items)
            
            for _ in range(items_to_extract):
                try:
                    item = await asyncio.wait_for(
                        self.request_queue.get(), timeout=0.1
                    )
                    temp_items.append(item)
                except (asyncio.TimeoutError, asyncio.QueueEmpty):
                    break
                    
            # ì •ë³´ ì¶”ì¶œ
            current_time = now_ms()
            for index, item in enumerate(temp_items):
                enqueued_at = item.get('enqueued_at', current_time)
                waiting_time = (current_time - enqueued_at) / 1000.0
                
                pending_requests.append({
                    "position": index + 1,
                    "request_id": item.get('request_id', 'unknown')[:8],
                    "message": item.get('message', '')[:50],
                    "username": item.get('username', 'unknown'),
                    "user_id": item.get('user_id'),
                    "enqueued_at": enqueued_at,
                    "waiting_time": round(waiting_time, 1)
                })
                
            # íì— ë‹¤ì‹œ ë„£ê¸° (ìˆœì„œ ë³´ì¡´)
            for item in temp_items:
                await self.request_queue.put(item)
                
        except Exception as e:
            logger.warning(f"Request Queue peek ì¤‘ ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨ì‹œ ì¶”ì¶œí•œ ì•„ì´í…œë“¤ì„ ë‹¤ì‹œ ë„£ê¸°
            for item in temp_items:
                try:
                    await self.request_queue.put(item)
                except Exception:
                    pass
                    
        return pending_requests
    
    async def _safe_peek_response_queue(self, max_items: int = 10) -> List[Dict[str, Any]]:
        """
        Response Queueì˜ ë‚´ìš©ì„ ì•ˆì „í•˜ê²Œ ì¡°íšŒ (Queue ìˆœì„œ ë³´ì¡´)
        
        Args:
            max_items: ìµœëŒ€ ì¡°íšŒí•  ì•„ì´í…œ ìˆ˜
            
        Returns:
            List[Dict]: ëŒ€ê¸° ì¤‘ì¸ MediaPacket ì •ë³´
        """
        if self.response_queue.qsize() == 0:
            return []
            
        pending_packets = []
        temp_packets = []
        
        try:
            # íì—ì„œ íŒ¨í‚·ë“¤ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
            items_to_extract = min(self.response_queue.qsize(), max_items)
            
            for _ in range(items_to_extract):
                try:
                    packet = await asyncio.wait_for(
                        self.response_queue.get(), timeout=0.1
                    )
                    temp_packets.append(packet)
                except (asyncio.TimeoutError, asyncio.QueueEmpty):
                    break
                    
            # ì •ë³´ ì¶”ì¶œ
            for index, packet in enumerate(temp_packets):
                # ì˜¤ë””ì˜¤ íŠ¸ë™ì—ì„œ ì˜ˆìƒ ì¬ìƒì‹œê°„ ì¶”ì¶œ
                duration = 0
                for track in packet.tracks:
                    if track.kind == "audio":
                        duration = max(duration, track.dur_ms / 1000.0)
                        
                pending_packets.append({
                    "position": index + 1,
                    "seq": packet.seq,
                    "hash": packet.hash[:8],
                    "tracks_count": len(packet.tracks),
                    "track_types": [track.kind for track in packet.tracks],
                    "duration": round(duration, 1),
                    "created_at": packet.t0_ms
                })
                
            # íì— ë‹¤ì‹œ ë„£ê¸° (ìˆœì„œ ë³´ì¡´)
            for packet in temp_packets:
                await self.response_queue.put(packet)
                
        except Exception as e:
            logger.warning(f"Response Queue peek ì¤‘ ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨ì‹œ ì¶”ì¶œí•œ íŒ¨í‚·ë“¤ì„ ë‹¤ì‹œ ë„£ê¸°
            for packet in temp_packets:
                try:
                    await self.response_queue.put(packet)
                except Exception:
                    pass
                    
        return pending_packets
    
    def reset_sequence(self):
        """ì‹œí€€ìŠ¤ ë²ˆí˜¸ ë¦¬ì…‹ (ë””ë²„ê¹…ìš©)"""
        self.seq = 0
        self._recent_hashes.clear()
        
    async def cleanup_cancelled_events(self):
        """ë§Œë£Œëœ ì·¨ì†Œ ì´ë²¤íŠ¸ ì •ë¦¬ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)"""
        current_time = now_ms()
        expired_events = []
        
        for request_id, event in self.cancellation_events.items():
            # 10ë¶„ ì´ìƒëœ ì´ë²¤íŠ¸ëŠ” ì •ë¦¬
            if hasattr(event, '_created_at'):
                if current_time - event._created_at > 600000:  # 10ë¶„
                    expired_events.append(request_id)
                    
        for request_id in expired_events:
            self.cancellation_events.pop(request_id, None)
            
        if expired_events:
            logger.info(f"ğŸ§¹ ë§Œë£Œëœ ì·¨ì†Œ ì´ë²¤íŠ¸ ì •ë¦¬: {len(expired_events)}ê°œ")