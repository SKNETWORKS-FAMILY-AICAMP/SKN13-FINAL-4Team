"""
ìŠ¤íŠ¸ë¦¬ë° ë„ë©”ì¸ ëª¨ë¸
DDD ì•„í‚¤í…ì²˜ ê¸°ë°˜ StreamSession, MediaPacket, MediaTrack êµ¬í˜„
Queue ê¸°ë°˜ ìˆœì°¨ ì²˜ë¦¬ ì‹œìŠ¤í…œ í¬í•¨
"""
from dataclasses import dataclass, field
import hashlib
import time
import asyncio
import logging
from typing import Literal, Optional, Dict, Any, List, AsyncGenerator
import uuid

logger = logging.getLogger(__name__)

def now_ms() -> int:
    """í˜„ì¬ ì‹œê°„ì„ ë°€ë¦¬ì´ˆë¡œ ë°˜í™˜"""
    return int(time.perf_counter() * 1000)

@dataclass(frozen=True)
class MediaTrack:
    """ë¯¸ë””ì–´ íŠ¸ë™ ê°’ ê°ì²´"""
    kind: Literal["audio", "video", "subtitle"]
    pts_ms: int  # Presentation Time Stamp (ìƒëŒ€ì  ì‹œê°„, ms)
    dur_ms: int  # Duration (ì§€ì† ì‹œê°„, ms)
    payload_ref: str  # ë¯¸ë””ì–´ ë°ì´í„° ì°¸ì¡° (URL ë˜ëŠ” ë°ì´í„°)
    codec: str  # ì½”ë± ì •ë³´
    meta: Optional[Dict[str, Any]] = None  # ë©”íƒ€ë°ì´í„°
    
    def __post_init__(self):
        """ìœ íš¨ì„± ê²€ì‚¬"""
        if self.pts_ms < 0:
            raise ValueError(f"Invalid pts_ms: {self.pts_ms} (must be >= 0)")
        if self.dur_ms <= 0:
            raise ValueError(f"Invalid dur_ms: {self.dur_ms} (must be > 0)")
        if not self.payload_ref:
            raise ValueError("payload_ref cannot be empty")
        if not self.codec:
            raise ValueError("codec cannot be empty")

@dataclass(frozen=True)
class MediaPacket:
    """ë¯¸ë””ì–´ íŒ¨í‚· ê°’ ê°ì²´"""
    v: int  # ë²„ì „
    session_id: str  # ì„¸ì…˜ ID
    seq: int  # ì‹œí€€ìŠ¤ ë²ˆí˜¸
    t0_ms: int  # ì„¸ì…˜ ì‹œì‘ ì‹œì  (monotonic time ms)
    tracks: List[MediaTrack]  # íŠ¸ë™ ëª©ë¡
    hash: str  # íŒ¨í‚· í•´ì‹œ (ë¬´ê²°ì„± ê²€ì¦ìš©)
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (WebSocket ì „ì†¡ìš©)"""
        return {
            "v": self.v,
            "session_id": self.session_id,
            "seq": self.seq,
            "t0": self.t0_ms,
            "tracks": [
                {
                    "kind": track.kind,
                    "pts": track.pts_ms,
                    "dur": track.dur_ms,
                    "payload_ref": track.payload_ref,
                    "codec": track.codec,
                    "meta": track.meta or {}
                }
                for track in self.tracks
            ],
            "hash": self.hash
        }

class StreamSession:
    """ìŠ¤íŠ¸ë¦¬ë° ì„¸ì…˜ ì• ê·¸ë¦¬ê²Œì´íŠ¸ ë£¨íŠ¸ - Queue ê¸°ë°˜ ìˆœì°¨ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, session_id: Optional[str] = None):
        self.session_id = session_id or uuid.uuid4().hex
        self.t0_ms = now_ms()  # ì„¸ì…˜ ì‹œì‘ ì‹œì 
        self.seq = 0  # ì‹œí€€ìŠ¤ ë²ˆí˜¸
        self._recent_hashes: List[str] = []  # ì¤‘ë³µ íŒ¨í‚· ë°©ì§€ìš© (ìµœê·¼ 50ê°œ ì €ì¥)
        
        # ğŸ†• Queue ê¸°ë°˜ ìˆœì°¨ ì²˜ë¦¬ ì‹œìŠ¤í…œ
        self.request_queue = asyncio.Queue()  # ìš”ì²­ ëŒ€ê¸°ì—´
        self.processing_lock = asyncio.Lock()  # ë™ì‹œ ì²˜ë¦¬ ë°©ì§€
        self.current_processing: Optional[Dict[str, Any]] = None  # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ìš”ì²­
        self.is_processing = False  # ì²˜ë¦¬ ìƒíƒœ í”Œë˜ê·¸
        
        # ğŸ†• Queue ë©”íŠ¸ë¦­ ë° ìƒíƒœ ì¶”ì 
        self.total_processed = 0  # ì´ ì²˜ë¦¬ëœ ìš”ì²­ ìˆ˜
        self.cancelled_requests = 0  # ì·¨ì†Œëœ ìš”ì²­ ìˆ˜
        self.processing_times = []  # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡ (ìµœê·¼ 10ê°œ)
        self.max_queue_length = 0  # ìµœëŒ€ í ê¸¸ì´ ê¸°ë¡
        self.recent_history = []  # ìµœê·¼ ì²˜ë¦¬ ì´ë ¥ (ìµœê·¼ 10ê°œ)
        
    def build_packet(self, tracks: List[MediaTrack]) -> MediaPacket:
        """
        ë¯¸ë””ì–´ íŒ¨í‚· ìƒì„±
        
        Args:
            tracks: ë¯¸ë””ì–´ íŠ¸ë™ ëª©ë¡
            
        Returns:
            MediaPacket: ìƒì„±ëœ ë¯¸ë””ì–´ íŒ¨í‚·
            
        Raises:
            ValueError: íŠ¸ë™ì´ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
        """
        if not tracks:
            raise ValueError("No tracks provided")
        
        # íŠ¸ë™ ìœ íš¨ì„± ê²€ì‚¬ëŠ” MediaTrack.__post_init__ì—ì„œ ì²˜ë¦¬
        
        # íŒ¨í‚· í•´ì‹œ ìƒì„± (íŠ¸ë™ ë‚´ìš© + ì‹œí€€ìŠ¤ + íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)
        current_time = now_ms()
        raw_content = "|".join(
            f"{t.kind}:{t.pts_ms}:{t.dur_ms}:{t.payload_ref}:{t.codec}"
            for t in tracks
        )
        # ì‹œí€€ìŠ¤ ë²ˆí˜¸ì™€ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
        unique_content = f"{self.seq}:{current_time}:{raw_content}"
        packet_hash = hashlib.sha256(unique_content.encode()).hexdigest()[:16]  # 16ìë¦¬ë¡œ ë‹¨ì¶•
        
        # ì¤‘ë³µ íŒ¨í‚· ì²´í¬
        if packet_hash in self._recent_hashes:
            raise ValueError(f"Duplicate packet detected: {packet_hash}")
        
        # ìµœê·¼ í•´ì‹œ ëª©ë¡ ê´€ë¦¬ (ìµœëŒ€ 50ê°œ)
        self._recent_hashes.append(packet_hash)
        if len(self._recent_hashes) > 50:
            self._recent_hashes = self._recent_hashes[-50:]
        
        # íŒ¨í‚· ìƒì„±
        packet = MediaPacket(
            v=1,  # ë²„ì „ 1
            session_id=self.session_id,
            seq=self.seq,
            t0_ms=self.t0_ms,
            tracks=tracks,
            hash=packet_hash
        )
        
        # ì‹œí€€ìŠ¤ ë²ˆí˜¸ ì¦ê°€
        self.seq += 1
        
        return packet
    
    def create_audio_track(self, audio_data_url: str, duration_ms: int, 
                          emotion: str = "neutral", voice: str = "default") -> MediaTrack:
        """ì˜¤ë””ì˜¤ íŠ¸ë™ ìƒì„± í—¬í¼"""
        return MediaTrack(
            kind="audio",
            pts_ms=0,  # ì¦‰ì‹œ ì‹œì‘
            dur_ms=duration_ms,
            payload_ref=audio_data_url,
            codec="audio/mpeg",
            meta={
                "emotion": emotion,
                "voice": voice
            }
        )
    
    def create_video_track(self, video_path: str, duration_ms: int, 
                          clip_type: str = "talk") -> MediaTrack:
        """ë¹„ë””ì˜¤ íŠ¸ë™ ìƒì„± í—¬í¼"""
        return MediaTrack(
            kind="video",
            pts_ms=0,  # ì¦‰ì‹œ ì‹œì‘
            dur_ms=duration_ms,
            payload_ref=video_path,
            codec="video/mp4",
            meta={
                "clip_type": clip_type
            }
        )
    
    def create_subtitle_track(self, subtitle_data: Dict[str, Any], 
                            duration_ms: int) -> MediaTrack:
        """ìë§‰ íŠ¸ë™ ìƒì„± í—¬í¼"""
        return MediaTrack(
            kind="subtitle",
            pts_ms=0,  # ì¦‰ì‹œ ì‹œì‘
            dur_ms=duration_ms,
            payload_ref=str(subtitle_data),  # JSON ë¬¸ìì—´ë¡œ ì €ì¥
            codec="text/json",
            meta=subtitle_data
        )
    
    async def enqueue_request(self, request_data: Dict[str, Any]):
        """
        ìš”ì²­ì„ íì— ì¶”ê°€í•˜ê³  í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì‘ì—… ì·¨ì†Œ
        
        Args:
            request_data: ì²˜ë¦¬í•  ìš”ì²­ ë°ì´í„° (message, user_id, streamer_config ë“±)
        """
        # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì‘ì—…ì´ ìˆìœ¼ë©´ ì·¨ì†Œ ì‹ í˜¸ ì „ì†¡
        if self.current_processing and 'cancel_event' in self.current_processing:
            self.current_processing['cancel_event'].set()
            logger.info(f"ğŸš« í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì‘ì—… ì·¨ì†Œ: {self.session_id[:8]}")
        
        # ìƒˆ ìš”ì²­ì„ íì— ì¶”ê°€
        await self.request_queue.put(request_data)
        logger.info(f"ğŸ“ ìš”ì²­ íì— ì¶”ê°€: {request_data.get('message', '')[:30]}... (í í¬ê¸°: {self.request_queue.qsize()})")
    
    async def process_queue(self, media_processor) -> AsyncGenerator[MediaPacket, None]:
        """
        íë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ MediaPacket ìƒì„±
        
        Args:
            media_processor: MediaProcessingHub ì¸ìŠ¤í„´ìŠ¤
            
        Yields:
            MediaPacket: ìƒì„±ëœ ë¯¸ë””ì–´ íŒ¨í‚·
        """
        while True:
            try:
                # ë‹¤ìŒ ìš”ì²­ ëŒ€ê¸°
                request_data = await self.request_queue.get()
                
                async with self.processing_lock:
                    # ì²˜ë¦¬ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                    start_time = now_ms()
                    
                    # ì·¨ì†Œ ì´ë²¤íŠ¸ ì„¤ì •
                    cancel_event = asyncio.Event()
                    request_data['cancel_event'] = cancel_event
                    request_data['start_time'] = start_time
                    self.current_processing = request_data
                    self.is_processing = True
                    
                    logger.info(f"ğŸ¬ ìš”ì²­ ì²˜ë¦¬ ì‹œì‘: {request_data.get('message', '')[:30]}... (seq: {self.seq})")
                    
                    try:
                        # MediaTrack ìƒì„± (ì·¨ì†Œ ê°€ëŠ¥)
                        tracks = await media_processor.generate_tracks_with_cancellation(
                            request_data, cancel_event
                        )
                        
                        if tracks and not cancel_event.is_set():
                            # ì²˜ë¦¬ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
                            processing_time = (now_ms() - start_time) / 1000.0  # ì´ˆ ë‹¨ìœ„
                            
                            # MediaPacket ìƒì„±
                            media_packet = self.build_packet(tracks)
                            logger.info(f"âœ… MediaPacket ìƒì„± ì™„ë£Œ: {media_packet.hash} (seq: {media_packet.seq})")
                            
                            # ì„±ê³µ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                            self._update_processing_metrics(processing_time, 'completed')
                            
                            yield media_packet
                        else:
                            # ì·¨ì†Œëœ ê²½ìš° ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                            processing_time = (now_ms() - start_time) / 1000.0
                            self._update_processing_metrics(processing_time, 'cancelled')
                            logger.info(f"ğŸš« ìš”ì²­ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤: {request_data.get('message', '')[:30]}")
                            
                    except Exception as e:
                        # ì‹¤íŒ¨í•œ ê²½ìš° ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                        processing_time = (now_ms() - start_time) / 1000.0
                        self._update_processing_metrics(processing_time, 'failed')
                        logger.error(f"âŒ ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                        
                    finally:
                        # ì²˜ë¦¬ ì™„ë£Œ ìƒíƒœ ë¦¬ì…‹
                        self.current_processing = None
                        self.is_processing = False
                        self.request_queue.task_done()
                        
            except Exception as e:
                logger.error(f"âŒ Queue ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    def get_session_info(self) -> Dict[str, Any]:
        """ì„¸ì…˜ ì •ë³´ ë°˜í™˜ (Queue ìƒíƒœ í¬í•¨)"""
        return {
            "session_id": self.session_id,
            "t0_ms": self.t0_ms,
            "current_seq": self.seq,
            "uptime_ms": now_ms() - self.t0_ms,
            "recent_hashes_count": len(self._recent_hashes),
            # ğŸ†• Queue ìƒíƒœ ì •ë³´
            "queue_length": self.request_queue.qsize(),
            "is_processing": self.is_processing,
            "current_request": self.current_processing.get('message', '')[:30] if self.current_processing else None
        }
    
    def get_detailed_queue_info(self) -> Dict[str, Any]:
        """
        ìƒì„¸í•œ Queue ìƒíƒœ ì •ë³´ ë°˜í™˜ (Debug Panelìš©)
        
        Returns:
            Dict containing detailed queue information for debugging
        """
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        avg_processing_time = (
            sum(self.processing_times) / len(self.processing_times) 
            if self.processing_times else 0
        )
        
        # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ìš”ì²­ ì •ë³´
        current_processing_info = None
        if self.current_processing:
            processing_duration = (
                (now_ms() - self.current_processing.get('start_time', 0)) / 1000
                if self.current_processing.get('start_time') else 0
            )
            current_processing_info = {
                "message": self.current_processing.get('message', ''),
                "username": self.current_processing.get('username', 'unknown'),
                "user_id": self.current_processing.get('user_id'),
                "start_time": self.current_processing.get('start_time'),
                "processing_duration": processing_duration,
                "room_group": self.current_processing.get('room_group')
            }
        
        # ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ë“¤ ì •ë³´ (Queue ë‚´ìš© ì•ˆì „í•˜ê²Œ ì¡°íšŒ)
        pending_requests = []
        try:
            # asyncio.Queue._queueëŠ” ë‚´ë¶€ êµ¬í˜„ì´ì§€ë§Œ ë””ë²„ê¹… ëª©ì ìœ¼ë¡œ ì‚¬ìš©
            temp_items = []
            
            # Queueì—ì„œ ëª¨ë“  ì•„ì´í…œì„ ì„ì‹œë¡œ êº¼ëƒ„
            while not self.request_queue.empty():
                try:
                    item = self.request_queue.get_nowait()
                    temp_items.append(item)
                except asyncio.QueueEmpty:
                    break
            
            # ëŒ€ê¸° ìš”ì²­ ì •ë³´ êµ¬ì„±
            for index, item in enumerate(temp_items):
                pending_requests.append({
                    "position": index + 1,
                    "message": item.get('message', '')[:50],
                    "username": item.get('username', 'unknown'),
                    "user_id": item.get('user_id'),
                    "timestamp": item.get('timestamp', 0),
                    "waiting_time": (now_ms() - item.get('timestamp', 0) * 1000) / 1000 if item.get('timestamp') else 0
                })
            
            # ì•„ì´í…œë“¤ì„ ë‹¤ì‹œ Queueì— ë„£ìŒ (ìˆœì„œ ìœ ì§€)
            for item in temp_items:
                self.request_queue.put_nowait(item)
                
        except Exception as e:
            logger.warning(f"Queue ë‚´ìš© ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            pending_requests = []
        
        return {
            "session_id": self.session_id,
            "timestamp": now_ms(),
            
            # ê¸°ë³¸ ìƒíƒœ
            "queue_length": self.request_queue.qsize(),
            "is_processing": self.is_processing,
            "current_seq": self.seq,
            "uptime_ms": now_ms() - self.t0_ms,
            
            # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ìš”ì²­
            "current_processing": current_processing_info,
            
            # ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ë“¤
            "pending_requests": pending_requests,
            
            # ë©”íŠ¸ë¦­
            "metrics": {
                "total_processed": self.total_processed,
                "cancelled_requests": self.cancelled_requests,
                "avg_processing_time": avg_processing_time,
                "max_queue_length": self.max_queue_length,
                "recent_processing_times": self.processing_times.copy(),
                "recent_hashes_count": len(self._recent_hashes)
            },
            
            # ìµœê·¼ ì²˜ë¦¬ ì´ë ¥
            "recent_history": self.recent_history.copy()
        }
    
    def _update_processing_metrics(self, processing_time: float, status: str = 'completed'):
        """ì²˜ë¦¬ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        if status == 'completed':
            self.total_processed += 1
            
            # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡ (ìµœê·¼ 10ê°œë§Œ ìœ ì§€)
            self.processing_times.append(processing_time)
            if len(self.processing_times) > 10:
                self.processing_times.pop(0)
                
        elif status == 'cancelled':
            self.cancelled_requests += 1
            
        elif status == 'failed':
            # ì‹¤íŒ¨í•œ ìš”ì²­ë„ ì¹´ìš´íŠ¸í•˜ì§€ë§Œ ë³„ë„ ì¶”ì  ì—†ìŒ (ë¡œê·¸ë¡œ ì¶©ë¶„)
            pass
        
        # ìµœëŒ€ í ê¸¸ì´ ì—…ë°ì´íŠ¸
        current_queue_length = self.request_queue.qsize()
        if current_queue_length > self.max_queue_length:
            self.max_queue_length = current_queue_length
        
        # ìµœê·¼ ì´ë ¥ ì—…ë°ì´íŠ¸ (ìµœê·¼ 10ê°œë§Œ ìœ ì§€)
        history_item = {
            "timestamp": now_ms(),
            "message": self.current_processing.get('message', '')[:30] if self.current_processing else '',
            "username": self.current_processing.get('username', 'unknown') if self.current_processing else '',
            "status": status,
            "processing_time": processing_time,
            "seq": self.seq - 1 if status == 'completed' else None
        }
        
        self.recent_history.insert(0, history_item)
        if len(self.recent_history) > 10:
            self.recent_history.pop()
        
        logger.debug(f"ğŸ“Š ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸: {status}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
    
    def reset_sequence(self):
        """ì‹œí€€ìŠ¤ ë²ˆí˜¸ ë¦¬ì…‹ (ë””ë²„ê¹…ìš©)"""
        self.seq = 0
        self._recent_hashes.clear()