{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf080dc-13a8-4851-8a96-6a999cd7d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4913a",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d68ce56fb4cc4710a4c33e456e4a1193"
     ]
    },
    "id": "27d4913a",
    "outputId": "6f0648c7-776d-4795-fb8f-b14af51558fb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# --- 1. 설정 ---\n",
    "# base_model = \"LGAI-EXAONE/EXAONE-4.0-32B\"\n",
    "# dataset_file = \"HONGCHA_DATASET.json\"\n",
    "# new_model_name = \"lgai\"\n",
    "\n",
    "# --- 2. 모델 및 토크나이저 로드 ---\n",
    "# 정상적인 환경에서는 아래 설정으로 작동해야 합니다.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# --- 3. LoRA 설정 (LoRA의 'LoRA') ---\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# --- 4. 학습 인자(Training Arguments) 설정 ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./{new_model_name}-results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"adamw_torch\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    bf16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# --- 5. SFTTrainer 설정 ---\n",
    "def formatting_prompts_func(example):\n",
    "    return f\"### User:\\n{example['instruction']}\\n\\n### Assistant:\\n{example['output']}\"\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files=dataset_file, split=\"train\")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    peft_config=peft_config,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    # max_seq_length=512, # VRAM 최적화를 위해 길이 제한\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "# --- 7. 모델 학습 시작 ---\n",
    "print(\"모델 학습을 시작합니다...\")\n",
    "trainer.train(resume_from_checkpoint=False)\n",
    "\n",
    "# --- 8. 최종 모델 저장 ---\n",
    "print(\"학습된 모델 어댑터를 저장합니다...\")\n",
    "trainer.model.save_pretrained(new_model_name)\n",
    "tokenizer.save_pretrained(new_model_name)\n",
    "\n",
    "print(f\"학습 완료! 모델이 '{new_model_name}' 디렉토리에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
